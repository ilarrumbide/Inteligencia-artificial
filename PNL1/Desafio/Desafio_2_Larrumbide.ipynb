{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade --force-reinstall numpy gensim pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dj-lwpNaYXlG",
        "outputId": "cbf737de-b416-41e2-bf58-f2749f7ce5b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/gensim/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: pytz, wrapt, tzdata, six, numpy, smart-open, scipy, python-dateutil, pandas, gensim\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.1 scipy-1.13.1 six-1.17.0 smart-open-7.1.0 tzdata-2025.1 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "six"
                ]
              },
              "id": "67ce8c7efb8c46e78f87a796a662634c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consignas:\n",
        "Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
        "Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
        "Graficarlos.\n",
        "Obtener conclusiones."
      ],
      "metadata": {
        "id": "CHMABgHDYnnn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lz-XJSsDTI8k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "wWn3n5JjHfs2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos"
      ],
      "metadata": {
        "id": "5kCKwIkqYbP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_avengers_scripts(file_paths, movie_names):\n",
        "    data = []\n",
        "    for file_path, movie_name in zip(file_paths, movie_names):\n",
        "        with open(file_path, 'r', encoding='latin-1') as f:\n",
        "            lines = f.read().splitlines()\n",
        "            for line in lines:\n",
        "                if line.strip():\n",
        "                    data.append({\n",
        "                        \"texto\": line,\n",
        "                        \"pelicula\": movie_name\n",
        "                    })\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"texto\", \"pelicula\"])\n",
        "    return df"
      ],
      "metadata": {
        "id": "gqFCMY5Ejbo1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = [\n",
        "        \"/content/Avengers.Age.of.Ultron.txt\",\n",
        "        \"/content/Avengers.Endgame.txt\",\n",
        "        \"/content/Avengers.Infinity.War.txt\",\n",
        "        \"/content/Avengers.txt\"\n",
        "    ]\n",
        "\n",
        "movie_names = [\n",
        "    \"Avengers: Age of Ultron\",\n",
        "    \"Avengers: Endgame\",\n",
        "    \"Avengers: Infinity War\",\n",
        "    \"The Avengers\"\n",
        "]\n",
        "\n",
        "df = load_avengers_scripts(file_paths, movie_names)\n",
        "\n",
        "print(df.head())\n",
        "print(f\"\\nTotal de líneas combinadas: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBBGS11ijeTj",
        "outputId": "c091415c-7bfe-4859-83fe-34724a485427"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               texto                 pelicula\n",
            "0                                (DISTANT EXPLOSION)  Avengers: Age of Ultron\n",
            "1  STRUCKER ON PA: Report to your stations immedi...  Avengers: Age of Ultron\n",
            "2                               This is not a drill.  Avengers: Age of Ultron\n",
            "3                               We are under attack!  Avengers: Age of Ultron\n",
            "4                   (SOLDIERS SHOUTING INDISTINCTLY)  Avengers: Age of Ultron\n",
            "\n",
            "Total de líneas combinadas: 7793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento"
      ],
      "metadata": {
        "id": "u49LGlzlYTUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "ehqL0qMYYU6r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNCqjQ4zfJDu",
        "outputId": "c7d446c1-70f6-47ea-b073-5ac6eaca671c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-23e21f4224e1>:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  sentence_tokens.append(text_to_word_sequence(row[0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zilcPR-ghQn",
        "outputId": "4475865a-7c5f-401d-c0bc-1631b5430baf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['distant', 'explosion'],\n",
              " ['strucker', 'on', 'pa', 'report', 'to', 'your', 'stations', 'immediately']]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Crear los vectores (word2vec)"
      ],
      "metadata": {
        "id": "JjpZmZvhYcYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobrecargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ],
      "metadata": {
        "id": "NLY3EvrSfxlA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)"
      ],
      "metadata": {
        "id": "c-dccE4GfyNM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el vocabulario con los tokens\n",
        "w2v_model.build_vocab(sentence_tokens)"
      ],
      "metadata": {
        "id": "vxrjuecEf0KV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiBOLEDzgnQR",
        "outputId": "f2814e0e-218a-4eb8-c2f1-9ba8994ae879"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 7793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9O4q8cJgnzV",
        "outputId": "e5cace6e-2def-4ff2-adfd-0f22b138f604"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Entrenar embeddings"
      ],
      "metadata": {
        "id": "7D_LOI-5Yfeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "import numpy as np\n",
        "\n",
        "class EarlyStoppingCallback(CallbackAny2Vec):\n",
        "    def __init__(self, patience=3, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_loss = np.inf\n",
        "        self.wait = 0\n",
        "        self.epoch = 0\n",
        "        self.loss_previous = 0.0\n",
        "        self.loss_history = []\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        current_loss = model.get_latest_training_loss()\n",
        "        epoch_loss = current_loss - self.loss_previous if self.epoch > 0 else current_loss\n",
        "        self.loss_history.append(epoch_loss)\n",
        "\n",
        "        print(f\"Epoch {self.epoch + 1} - Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        if self.best_loss - epoch_loss > self.min_delta:\n",
        "            self.best_loss = epoch_loss\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                print(f\"Early stopping at epoch {self.epoch + 1}\")\n",
        "                raise StopIteration  # Gensim lo va a capturar y cortar el entrenamiento\n",
        "\n",
        "        self.loss_previous = current_loss\n",
        "        self.epoch += 1\n"
      ],
      "metadata": {
        "id": "QDEiy6PQHZsM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStoppingCallback(patience=5, min_delta=0.01)"
      ],
      "metadata": {
        "id": "d7ZZv_gWHdHw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    w2v_model.train(\n",
        "        sentence_tokens,\n",
        "        total_examples=w2v_model.corpus_count,\n",
        "        epochs=100,\n",
        "        compute_loss=True,\n",
        "        callbacks=[callback(), EarlyStoppingCallback(patience=5, min_delta=0.01)]\n",
        "    )\n",
        "except StopIteration:\n",
        "    print(\"Entrenamiento detenido por Early Stopping.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c0KPqp8gsBM",
        "outputId": "9fc7e7b8-a0bd-44ec-dabe-2bcb0410f153"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 129888.1015625\n",
            "Epoch 1 - Loss: 129888.1016\n",
            "Loss after epoch 1: 127880.1953125\n",
            "Epoch 2 - Loss: 127880.1953\n",
            "Loss after epoch 2: 128142.890625\n",
            "Epoch 3 - Loss: 128142.8906\n",
            "Loss after epoch 3: 127139.03125\n",
            "Epoch 4 - Loss: 127139.0312\n",
            "Loss after epoch 4: 125698.78125\n",
            "Epoch 5 - Loss: 125698.7812\n",
            "Loss after epoch 5: 124499.25\n",
            "Epoch 6 - Loss: 124499.2500\n",
            "Loss after epoch 6: 125712.4375\n",
            "Epoch 7 - Loss: 125712.4375\n",
            "Loss after epoch 7: 124422.375\n",
            "Epoch 8 - Loss: 124422.3750\n",
            "Loss after epoch 8: 119965.4375\n",
            "Epoch 9 - Loss: 119965.4375\n",
            "Loss after epoch 9: 120029.25\n",
            "Epoch 10 - Loss: 120029.2500\n",
            "Loss after epoch 10: 119626.375\n",
            "Epoch 11 - Loss: 119626.3750\n",
            "Loss after epoch 11: 119445.25\n",
            "Epoch 12 - Loss: 119445.2500\n",
            "Loss after epoch 12: 121587.125\n",
            "Epoch 13 - Loss: 121587.1250\n",
            "Loss after epoch 13: 119591.625\n",
            "Epoch 14 - Loss: 119591.6250\n",
            "Loss after epoch 14: 119542.25\n",
            "Epoch 15 - Loss: 119542.2500\n",
            "Loss after epoch 15: 118991.625\n",
            "Epoch 16 - Loss: 118991.6250\n",
            "Loss after epoch 16: 120052.875\n",
            "Epoch 17 - Loss: 120052.8750\n",
            "Loss after epoch 17: 114572.875\n",
            "Epoch 18 - Loss: 114572.8750\n",
            "Loss after epoch 18: 114802.75\n",
            "Epoch 19 - Loss: 114802.7500\n",
            "Loss after epoch 19: 112941.75\n",
            "Epoch 20 - Loss: 112941.7500\n",
            "Loss after epoch 20: 112254.75\n",
            "Epoch 21 - Loss: 112254.7500\n",
            "Loss after epoch 21: 115092.5\n",
            "Epoch 22 - Loss: 115092.5000\n",
            "Loss after epoch 22: 112603.0\n",
            "Epoch 23 - Loss: 112603.0000\n",
            "Loss after epoch 23: 114039.25\n",
            "Epoch 24 - Loss: 114039.2500\n",
            "Loss after epoch 24: 113302.75\n",
            "Epoch 25 - Loss: 113302.7500\n",
            "Loss after epoch 25: 113317.75\n",
            "Epoch 26 - Loss: 113317.7500\n",
            "Early stopping at epoch 26\n",
            "Entrenamiento detenido por Early Stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Ensayar"
      ],
      "metadata": {
        "id": "BjTUnpEJYicJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"thor\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdMPqCDGgt3Q",
        "outputId": "8e5bc272-5a8c-4b3f-e1aa-d1dac639c138"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"everyone's\", 0.41773292422294617),\n",
              " ('package', 0.41563108563423157),\n",
              " ('potts', 0.41021886467933655),\n",
              " ('howard', 0.40618517994880676),\n",
              " ('jet', 0.39711329340934753),\n",
              " ('bigger', 0.38838642835617065),\n",
              " ('heading', 0.3873836100101471),\n",
              " ('dinner', 0.38202062249183655),\n",
              " ('copy', 0.37993738055229187),\n",
              " ('mr', 0.37983185052871704)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➡️ Conclusión: el modelo aprendió que \"thor\" se comporta como un nombre de personaje importante, aunque no logra una agrupación semántica muy precisa (no aparecen dioses, héroes o enemigos directos como \"loki\", \"odin\", etc.)."
      ],
      "metadata": {
        "id": "mO20k6rUIz2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"hammer\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMPKGTUggy3b",
        "outputId": "95a87395-bac6-420a-b7e6-b60e178dffe2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('game', 0.5320076942443848),\n",
              " ('hero', 0.5127865672111511),\n",
              " ('deep', 0.49481895565986633),\n",
              " ('elevator', 0.49120378494262695),\n",
              " ('powering', 0.48760756850242615),\n",
              " ('chitauri', 0.4864158630371094),\n",
              " ('portal', 0.482796311378479),\n",
              " ('men', 0.48011118173599243),\n",
              " ('axe', 0.46707069873809814),\n",
              " ('woman', 0.4629170298576355)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔍 Interpretación: Estas palabras están relacionadas con batallas, armas y elementos de acción o ciencia ficción. \"axe\" es una herramienta similar a \"hammer\", \"chitauri\" son enemigos en la saga, y \"portal\" aparece en escenas clave de pelea.\n",
        "\n",
        "➡️ Conclusión: el modelo entendió \"hammer\" como un objeto asociado a lucha o poder, y lo relaciona con conceptos de combate o escenas épicas."
      ],
      "metadata": {
        "id": "-ZKHWJ80I4Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"thanos\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6Tp8UTUg2T1",
        "outputId": "e574231a-b853-4721-d357-d4c86995a5c3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('yours', 0.42224380373954773),\n",
              " ('destiny', 0.4020102918148041),\n",
              " ('born', 0.393685519695282),\n",
              " ('saying', 0.39201289415359497),\n",
              " ('starts', 0.39084574580192566),\n",
              " ('heist', 0.3893267810344696),\n",
              " ('lila', 0.3791799247264862),\n",
              " ('backup', 0.3782801926136017),\n",
              " ('turned', 0.3722943365573883),\n",
              " ('fall', 0.3720740079879761)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔍 Interpretación: A diferencia de \"thor\" o \"hammer\", acá vemos una carga más filosófica o narrativa: \"destiny\", \"born\", \"saying\", \"fall\", lo cual concuerda con el personaje Thanos, que suele hablar de propósito, destino, sacrificio.\n",
        "\n",
        "➡️ Conclusión: el modelo captó bien el tono reflexivo y dramático del personaje. No lo asocia tanto con enemigos o peleas, sino con temas existenciales."
      ],
      "metadata": {
        "id": "3pY_UT7lI9GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"reality\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn3_PU2Ng4J0",
        "outputId": "943193d2-e81d-4d9d-d95e-54fb7deee807"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('reading', 0.5089521408081055),\n",
              " ('metal', 0.4953494966030121),\n",
              " ('secret', 0.46797508001327515),\n",
              " ('push', 0.4611196517944336),\n",
              " ('signature', 0.45417845249176025),\n",
              " ('rhodes', 0.44240427017211914),\n",
              " ('failure', 0.4386778771877289),\n",
              " ('pal', 0.4375308156013489),\n",
              " ('heroes', 0.43654781579971313),\n",
              " ('damn', 0.43092602491378784)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔍 Interpretación: Aunque “reality” podría esperarse que esté asociada al contexto del reality stone, el modelo no parece haber captado ese significado directamente. En cambio, lo asocia con:\n",
        "\n",
        "Acciones: \"reading\", \"push\", \"failure\"\n",
        "\n",
        "Elementos confidenciales: \"secret\", \"signature\"\n",
        "\n",
        "➡️ Conclusión: el modelo asocia reality a conceptos ocultos, documentales o situaciones críticas, probablemente reflejando su uso en escenas con tensión, decisiones, o información reveladora."
      ],
      "metadata": {
        "id": "qv1iL3uaJKFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"vision\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWxEzCPSg6P7",
        "outputId": "367c7579-3ff5-4251-cda3-8fd08ff11868"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('outside', 0.450346440076828),\n",
              " ('situation', 0.44929176568984985),\n",
              " ('boy', 0.43770068883895874),\n",
              " ('gem', 0.43396615982055664),\n",
              " ('language', 0.4299742579460144),\n",
              " ('hydra', 0.4078928232192993),\n",
              " ('backup', 0.40571439266204834),\n",
              " ('somebody', 0.40481793880462646),\n",
              " ('field', 0.3897557556629181),\n",
              " ('strucker', 0.38845503330230713)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➡️ Conclusión: el modelo representa a vision más como personaje asociado a análisis, tecnología y contexto bélico/científico, reflejando bien su rol en las películas."
      ],
      "metadata": {
        "id": "v9MnC_VaJSoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"iron\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iWf332IIWRx",
        "outputId": "e290a0cd-7a3f-4c44-80dc-fdd309eef308"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unsafe', 0.5384253263473511),\n",
              " ('beyond', 0.5145337581634521),\n",
              " ('next', 0.5113049149513245),\n",
              " ('boom', 0.503582239151001),\n",
              " ('grunts', 0.4839480519294739),\n",
              " ('soldiers', 0.482605904340744),\n",
              " ('swear', 0.4809715151786804),\n",
              " ('definitely', 0.4772692620754242),\n",
              " ('metal', 0.4690863788127899),\n",
              " ('side', 0.46679747104644775)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➡️ Conclusión: el modelo representa iron como un término ligado a guerra, peligro y futurismo, probablemente por su uso frecuente en frases de Iron Man o descripciones tecnológicas."
      ],
      "metadata": {
        "id": "NtheCswRJXna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"captain\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocBCEnQ5IbTu",
        "outputId": "58e64eac-5250-4bbd-c66e-d8ecad58f55e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('america', 0.6454978585243225),\n",
              " ('7', 0.49956169724464417),\n",
              " ('artificial', 0.4503221809864044),\n",
              " ('form', 0.44700801372528076),\n",
              " ('threat', 0.4435817301273346),\n",
              " ('whoa', 0.4395093321800232),\n",
              " ('floor', 0.43047085404396057),\n",
              " ('drax', 0.40974196791648865),\n",
              " ('free', 0.40720638632774353),\n",
              " ('easy', 0.40625327825546265)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➡️ Conclusión: el modelo entendió captain como una figura clave asociada a America, libertad y amenazas, captando su rol de líder y su origen artificial dentro de la historia."
      ],
      "metadata": {
        "id": "gHn4KclwKgoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"war\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQLalpY9JkOZ",
        "outputId": "f8538fcb-28cd-4403-f38f-d4bc7df9c15c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('history', 0.4878173768520355),\n",
              " ('machine', 0.4546477794647217),\n",
              " ('jump', 0.43689024448394775),\n",
              " ('also', 0.4345536530017853),\n",
              " ('starts', 0.43043407797813416),\n",
              " ('path', 0.4241401255130768),\n",
              " ('asgardian', 0.4198858439922333),\n",
              " ('heist', 0.41982656717300415),\n",
              " ('body', 0.4192831814289093),\n",
              " ('reactor', 0.4172009825706482)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➡️ Conclusión: el modelo entendió war más por su contexto en la historia que como guerra literal, relacionándolo con estrategia, tecnología y personajes como War Machine."
      ],
      "metadata": {
        "id": "89FruzsgKTPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"stones\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNCWAheJJzHu",
        "outputId": "bf9a06f7-1882-4f5a-b3ba-98af3cf398ec"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('infinity', 0.5245112180709839),\n",
              " ('cradle', 0.5156025886535645),\n",
              " ('reading', 0.45838484168052673),\n",
              " ('weeks', 0.4581387937068939),\n",
              " ('went', 0.44630536437034607),\n",
              " ('humans', 0.4406774044036865),\n",
              " ('whole', 0.44021517038345337),\n",
              " (\"'em\", 0.43786755204200745),\n",
              " ('days', 0.43601787090301514),\n",
              " ('together', 0.4350634515285492)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➡️ Conclusión: el modelo entendió stones como parte de las infinity stones, con referencias a tiempo, humanidad y escenas donde se habla de reunirlas, mostrando que captó bien su peso en la trama."
      ],
      "metadata": {
        "id": "RLNHtou9KlD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Visualizar"
      ],
      "metadata": {
        "id": "JZ-xJiH_YjG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def reduce_dimensions(model, num_dimensions = 2 ):\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index_to_key)\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    return vectors, labels"
      ],
      "metadata": {
        "id": "Tel5kH8Dg-NV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "vecs, labels = reduce_dimensions(w2v_model)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "SZeQLbPehAJz",
        "outputId": "d6a12c0e-e7fe-4366-cc78-4fe2229eb85e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7d0734a5a160>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
            "    self._make_controller_from_path(filepath)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1187, in _make_controller_from_path\n",
            "    lib_controller = controller_class(\n",
            "                     ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
            "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: dlopen() error\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7af43815-ac6c-4b8f-ae4d-b7f2f3ddb355\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7af43815-ac6c-4b8f-ae4d-b7f2f3ddb355\")) {                    Plotly.newPlot(                        \"7af43815-ac6c-4b8f-ae4d-b7f2f3ddb355\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"you\",\"the\",\"i\",\"to\",\"a\",\"it\",\"we\",\"is\",\"that\",\"of\",\"and\",\"this\",\"in\",\"on\",\"what\",\"me\",\"not\",\"no\",\"i'm\",\"it's\",\"are\",\"for\",\"have\",\"he\",\"know\",\"be\",\"all\",\"your\",\"do\",\"don't\",\"my\",\"right\",\"but\",\"you're\",\"was\",\"if\",\"get\",\"got\",\"so\",\"here\",\"out\",\"yeah\",\"up\",\"one\",\"like\",\"can\",\"with\",\"just\",\"time\",\"him\",\"go\",\"that's\",\"there\",\"they\",\"gonna\",\"about\",\"now\",\"stark\",\"will\",\"did\",\"we're\",\"he's\",\"need\",\"back\",\"think\",\"okay\",\"how\",\"come\",\"at\",\"them\",\"well\",\"oh\",\"an\",\"us\",\"our\",\"where\",\"going\",\"want\",\"down\",\"as\",\"from\",\"his\",\"way\",\"could\",\"then\",\"didn't\",\"can't\",\"why\",\"hey\",\"see\",\"good\",\"been\",\"stone\",\"thanos\",\"take\",\"who\",\"would\",\"were\",\"people\",\"man\",\"tell\",\"look\",\"ultron\",\"when\",\"something\",\"or\",\"i'll\",\"only\",\"am\",\"thing\",\"had\",\"off\",\"really\",\"yes\",\"stones\",\"there's\",\"more\",\"never\",\"has\",\"what's\",\"guys\",\"little\",\"even\",\"say\",\"sorry\",\"should\",\"stop\",\"i've\",\"thor\",\"her\",\"some\",\"find\",\"too\",\"still\",\"please\",\"world\",\"because\",\"make\",\"sir\",\"power\",\"guy\",\"let\",\"they're\",\"life\",\"loki\",\"give\",\"than\",\"jarvis\",\"very\",\"let's\",\"isn't\",\"banner\",\"tony\",\"god\",\"everything\",\"coming\",\"put\",\"these\",\"doing\",\"she\",\"better\",\"mean\",\"two\",\"barton\",\"long\",\"might\",\"help\",\"kill\",\"nothing\",\"lot\",\"lost\",\"other\",\"by\",\"tesseract\",\"does\",\"thought\",\"maybe\",\"work\",\"made\",\"years\",\"over\",\"much\",\"call\",\"avengers\",\"wait\",\"bring\",\"cap\",\"any\",\"wanna\",\"things\",\"before\",\"doesn't\",\"thank\",\"keep\",\"every\",\"sure\",\"new\",\"again\",\"trying\",\"said\"],\"x\":[0.86204875,0.47132456,1.1169102,0.76694375,0.53126514,0.90400344,0.9694359,0.4808607,0.7257879,0.41970715,0.78531253,0.667064,0.44296104,0.38051084,0.8768909,1.0747122,0.4495045,0.5845631,0.24537793,0.60104245,0.3621019,0.56980807,1.2506838,0.98002166,0.8049673,1.0038741,0.9662423,0.77216446,1.023946,1.4053752,0.93477,0.553139,0.8964527,0.46787593,0.9249166,0.9741172,1.4102755,0.4867029,0.71212584,0.4456081,0.811796,-0.23145196,0.4576719,0.71425486,-0.10080727,2.1331851,0.6635924,0.64620584,1.3193882,1.1992087,2.0125818,0.43831003,0.48768938,1.2301385,0.093487345,1.1308621,0.6029752,-0.04747389,2.0324557,1.6214378,-0.8010002,-0.041244056,0.5023308,1.3064109,1.0628614,-0.71056306,1.1642654,1.1673211,-0.15105872,3.6915524,-0.050759688,-2.3905063,1.2836627,0.90059876,0.37521237,2.181413,0.08214437,1.3686296,3.513463,4.0661674,0.2478677,0.9050013,0.27020994,2.534081,1.3099239,1.6367863,1.140219,0.45762992,-2.8720562,1.194611,0.039871395,0.9262443,2.2958102,1.4812659,3.0974581,0.22131583,0.38126633,1.2087458,-1.6303829,-1.8971729,2.4734538,-1.6815395,-0.25292125,1.3647246,1.652917,0.38635364,4.382933,-0.14291911,-3.7835152,2.3472185,2.5514302,5.146402,0.9416561,-1.0028591,-1.0576029,-0.37118357,1.5208932,2.4916835,4.8541255,-3.050564,1.395755,-2.5007274,1.4036704,0.18353364,-0.8438826,1.6157405,0.46675715,4.5333414,-2.4730701,4.503013,1.1209447,2.8252296,0.53034234,4.02613,-4.0030956,-2.711484,0.6050822,2.0539055,-1.1211238,-1.8600461,0.8924372,1.0396101,2.06304,2.4009793,0.5683064,4.5661426,-0.9491576,-4.0442324,-1.0022278,3.5620444,3.205284,2.755593,4.0133243,1.6534084,3.4132667,-1.5279969,0.23124532,0.37011424,-0.55638504,4.5259686,4.777686,1.5621444,-0.63355434,-2.4792254,3.6495955,0.11219087,3.9155326,3.4960222,1.7396055,-3.3517594,0.09093112,2.8935704,0.4335397,2.2969637,1.2109649,2.0524058,3.397519,1.8841121,-1.6355754,0.90715,-4.918913,2.6944182,-0.053074863,-0.34751782,-2.8937004,3.8690658,2.4624515,1.144669,1.966337,3.8078482,3.3543565,0.8599644,-1.9138318,1.6959692,-2.8214824,-0.8019869,-4.783935,3.9647944,-3.7522926,3.1891603],\"xaxis\":\"x\",\"y\":[0.71443,0.17903848,0.85072994,0.5706963,0.39151132,0.8943266,0.44351575,0.40227354,0.8729997,0.10111712,0.32972038,0.6648119,-0.001802611,0.16874819,1.053186,0.7702992,0.7671435,0.93391305,1.1759759,0.8341419,-0.59025615,0.49481773,0.4868326,0.7211093,1.2397296,0.5020055,0.24494271,0.45149308,1.2857056,1.1798854,0.24719866,0.6583618,0.9613204,0.79188037,0.81012535,0.98567325,0.0051965974,-1.2401283,1.2110565,0.26297316,-0.09883764,1.635121,0.5374246,0.064658284,1.2909939,0.9570228,0.120958626,1.0721102,-0.614228,0.73134243,0.5012739,2.0324464,0.40722495,0.71435744,2.1790645,0.3205444,0.7438046,0.5326155,1.2069238,0.9805687,-1.1706982,0.67980427,0.50629485,0.1659915,1.595821,1.6115384,1.3650482,0.72976285,0.8211482,-0.6208725,1.3239342,1.5083532,-5.153782,0.4785912,0.10347912,0.24267237,0.75968885,1.1250249,3.6389246,-2.1440685,-0.65938115,0.5880276,0.62316936,1.4239563,0.34354597,1.0101402,3.6346722,1.561905,1.0591878,0.8982243,3.0431354,2.0856557,-0.49652806,-0.03695638,0.27517214,0.36118641,0.4944267,-0.94156104,-0.2521479,0.6996915,0.869977,2.085033,0.7142543,-0.36435845,1.7122228,0.27885476,0.004164687,5.32298,1.6182164,2.5743876,-2.0081124,-0.6529295,2.2307441,1.4096704,-4.779426,5.611835,-1.4463673,3.1805353,0.66560614,2.6665785,2.462379,3.3208075,1.0426805,1.8900832,3.2906137,1.3805743,3.225021,-1.1937215,2.6294596,2.8294876,0.4056786,-0.20212847,3.2831573,2.0500817,0.4069015,4.5047,1.996792,1.2266649,2.311397,-3.0142426,5.205881,3.2550702,2.207433,-3.0511642,5.3550873,1.9858396,-3.5444727,1.5304381,3.2027786,0.65735805,1.3749454,4.7828703,-3.3105006,3.248896,1.6712147,2.0895703,-1.6751945,-0.96511143,0.35107884,0.67463064,0.70431805,2.019007,-4.238947,-0.702571,3.135788,4.123721,1.7748979,-2.2457817,-2.5756283,3.7472796,-3.1161504,-3.984217,-1.3224461,-0.5942893,1.801796,0.73731905,2.0220914,0.12134681,5.405293,-3.4504666,-0.5843555,4.383367,2.1208227,0.7581491,1.994243,-0.92785746,-4.736283,2.3734374,1.1416874,1.3982574,2.579421,1.5360478,4.1812806,0.20931247,-1.2697045,2.2051103,-1.55962,2.1998956,2.0240276,-0.8931156],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7af43815-ac6c-4b8f-ae4d-b7f2f3ddb355');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los embedddings en 3D\n",
        "\n",
        "vecs, labels = reduce_dimensions(w2v_model,3)\n",
        "\n",
        "fig = px.scatter_3d(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], z=vecs[:MAX_WORDS,2],text=labels[:MAX_WORDS])\n",
        "fig.update_traces(marker_size = 2)\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8YTTD6FehBso",
        "outputId": "97562e30-d285-4f38-b075-645952fc1b67"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d934c4de-31e6-4939-9e06-2fdfc570435b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d934c4de-31e6-4939-9e06-2fdfc570435b\")) {                    Plotly.newPlot(                        \"d934c4de-31e6-4939-9e06-2fdfc570435b\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"size\":2},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"you\",\"the\",\"i\",\"to\",\"a\",\"it\",\"we\",\"is\",\"that\",\"of\",\"and\",\"this\",\"in\",\"on\",\"what\",\"me\",\"not\",\"no\",\"i'm\",\"it's\",\"are\",\"for\",\"have\",\"he\",\"know\",\"be\",\"all\",\"your\",\"do\",\"don't\",\"my\",\"right\",\"but\",\"you're\",\"was\",\"if\",\"get\",\"got\",\"so\",\"here\",\"out\",\"yeah\",\"up\",\"one\",\"like\",\"can\",\"with\",\"just\",\"time\",\"him\",\"go\",\"that's\",\"there\",\"they\",\"gonna\",\"about\",\"now\",\"stark\",\"will\",\"did\",\"we're\",\"he's\",\"need\",\"back\",\"think\",\"okay\",\"how\",\"come\",\"at\",\"them\",\"well\",\"oh\",\"an\",\"us\",\"our\",\"where\",\"going\",\"want\",\"down\",\"as\",\"from\",\"his\",\"way\",\"could\",\"then\",\"didn't\",\"can't\",\"why\",\"hey\",\"see\",\"good\",\"been\",\"stone\",\"thanos\",\"take\",\"who\",\"would\",\"were\",\"people\",\"man\",\"tell\",\"look\",\"ultron\",\"when\",\"something\",\"or\",\"i'll\",\"only\",\"am\",\"thing\",\"had\",\"off\",\"really\",\"yes\",\"stones\",\"there's\",\"more\",\"never\",\"has\",\"what's\",\"guys\",\"little\",\"even\",\"say\",\"sorry\",\"should\",\"stop\",\"i've\",\"thor\",\"her\",\"some\",\"find\",\"too\",\"still\",\"please\",\"world\",\"because\",\"make\",\"sir\",\"power\",\"guy\",\"let\",\"they're\",\"life\",\"loki\",\"give\",\"than\",\"jarvis\",\"very\",\"let's\",\"isn't\",\"banner\",\"tony\",\"god\",\"everything\",\"coming\",\"put\",\"these\",\"doing\",\"she\",\"better\",\"mean\",\"two\",\"barton\",\"long\",\"might\",\"help\",\"kill\",\"nothing\",\"lot\",\"lost\",\"other\",\"by\",\"tesseract\",\"does\",\"thought\",\"maybe\",\"work\",\"made\",\"years\",\"over\",\"much\",\"call\",\"avengers\",\"wait\",\"bring\",\"cap\",\"any\",\"wanna\",\"things\",\"before\",\"doesn't\",\"thank\",\"keep\",\"every\",\"sure\",\"new\",\"again\",\"trying\",\"said\"],\"x\":[-3.654817,5.598107,-8.74405,4.3505573,0.28453898,-5.625889,-10.288081,0.1455961,-1.7330976,2.5064046,12.302471,2.0326774,9.234704,10.053777,-17.070797,-10.855544,-9.361584,-47.119793,-21.621857,-29.590755,-65.16026,-6.7138033,-4.236234,-1.2436486,-20.57421,26.227972,-1.9946482,29.423195,-23.708761,-11.408967,-6.0315223,-36.51839,-41.64383,-0.82996094,-10.316826,-12.873351,3.484011,6.7440424,-81.086845,-41.526546,-5.4329534,-48.406193,58.073254,47.819347,-46.117344,2.096274,17.453573,-5.1686935,26.617447,-1.4131161,-10.878523,-10.049736,-53.201492,-6.714734,-37.40581,8.862986,-15.302422,-58.368423,-34.028255,44.00801,-37.453262,-40.51883,-17.678083,3.1441453,-37.64734,-45.538826,-50.233543,-15.243012,-30.373718,-10.536126,-58.933487,-46.638615,61.69672,42.65757,20.448952,-9.992878,-36.433598,-70.82786,-30.124432,-1.4911352,47.512447,-34.405453,-2.8023562,15.375464,-53.815315,-29.162115,-11.126936,-22.22618,-32.455555,-11.016878,-23.638779,-9.536665,53.332546,33.54563,39.888348,-73.4033,33.17881,14.023391,16.63842,19.588509,-16.47066,-54.823784,-23.63456,33.671753,35.26857,27.976084,37.75751,-15.729109,-8.592351,18.042383,29.743315,0.12670374,-4.7083683,-80.71925,34.853405,-73.73754,74.64547,-34.05689,57.743347,-55.052002,33.71903,67.68502,-24.567686,-27.999134,-25.750937,-10.922509,-21.60875,-8.131709,-14.563319,19.008316,-5.002876,-13.747302,-33.070904,-6.3355284,-34.878475,7.4437437,-18.721695,49.15152,-49.20726,55.994427,44.643856,-13.608216,2.4965348,17.829327,-25.86028,25.833046,45.328663,1.7995679,-74.044014,20.402594,-6.9153895,-0.86768305,-40.07432,-50.44853,35.678383,-58.897007,10.466347,-64.6062,-19.53134,4.989547,21.363844,-22.97614,38.578663,-10.990024,3.7247736,26.338163,-4.647146,-10.594751,-18.832275,19.40647,-37.32026,38.37936,60.821384,27.488634,-7.7218704,-9.406894,-37.710304,21.824753,-18.39809,28.887333,-34.441864,69.47126,-40.846138,23.572674,-72.46318,4.778382,-57.222023,54.481113,-61.7641,41.072773,-43.90468,-2.5187519,-56.72269,-5.7966986,15.34641,-53.997658,63.475723,-49.74709,-24.012892,11.910555],\"y\":[-1.0126492,-3.6447618,-6.2399797,-12.326138,6.258596,-12.178217,-1.4026533,11.022144,-11.489832,2.2388053,-5.4985995,-3.7566063,4.6093445,-12.45009,-10.239545,-7.7933598,-15.62128,-8.9528,-6.223177,30.63693,-42.323822,-0.011636386,-19.218248,-12.04344,-2.0370986,-39.63732,1.5387884,24.920382,-12.876506,-18.966745,10.161233,43.76204,41.345894,-70.20869,-31.156443,-19.019342,-7.770754,10.729584,-11.437254,0.54091614,45.477123,-56.57986,-21.188934,-32.202885,-42.407227,-52.43271,-31.42109,-47.772446,52.935482,-20.410673,6.597985,-70.45788,3.940298,-4.452813,-34.392902,3.843829,-34.95125,26.228384,-62.776913,46.68324,29.27711,66.68991,-52.037197,-2.154827,-43.526485,-60.02737,-55.47962,4.3876886,12.065454,11.8913965,31.754976,5.7752323,9.511994,-20.542334,-73.478226,0.262812,-53.913177,-22.821217,-59.35036,32.48711,-9.470309,23.080822,-41.52165,-66.25337,5.565364,59.892746,-47.560055,10.018435,-31.492752,-78.637825,-42.760437,72.96339,-40.588375,45.56707,-37.553722,1.5707945,1.7398424,-5.616346,-42.632404,-52.898464,-24.641249,36.001205,69.18778,59.622173,-48.86737,-36.496727,-7.9296627,-27.534323,-33.112732,24.52503,-30.445854,77.3366,28.16174,1.402991,44.449017,-14.808068,27.897005,30.342165,-26.718815,25.716711,-50.148586,-27.355597,-63.97328,58.612835,-41.81952,11.292722,-25.854355,67.325066,-62.917435,-20.099665,-42.07709,16.955402,-32.88333,28.487947,22.454279,66.995995,74.93594,-59.419582,29.609476,0.11646666,-4.480052,-35.672237,-13.607454,27.351597,50.775043,-71.11549,18.226618,-40.450104,25.221107,-34.737556,-29.022776,-30.158836,-1.0658867,17.356293,41.899067,-6.1955943,52.957897,21.97131,-0.5473119,0.5000008,-0.12688102,62.247112,36.48784,27.63997,-16.81606,-56.172176,-57.891376,39.016476,39.242077,-29.516699,55.11301,-32.487633,-44.661137,-21.757832,-6.347769,-18.45612,36.79913,-32.32776,41.619934,45.854782,-14.189733,-27.204773,62.444653,-77.67157,-23.970308,56.199574,-14.060941,-58.50021,-29.412832,-57.380737,-17.537436,-71.69787,-31.794859,62.33918,-48.600395,-34.158424,47.57489,56.484364,-62.413937,-62.96798],\"z\":[-1.7424877,-5.660201,8.914452,0.16710752,1.8654231,1.584399,2.4347346,-7.9791217,-8.935557,-12.14452,1.4897218,5.4045486,-2.0353463,-7.5090313,2.1174545,-6.483916,-14.613129,-12.065082,-7.8559275,-9.142707,20.593977,-10.6852865,-30.756437,10.907882,9.458376,-7.470012,14.1932535,-61.74189,10.115388,8.046913,-19.002842,14.406488,-10.842856,13.593642,-31.25069,-4.143311,-16.63544,19.073162,-2.2843263,64.59447,62.386845,-14.934238,-50.25947,-23.526636,48.179165,6.8080754,-71.94311,58.28559,2.9461105,-1.9220665,9.578699,-32.754856,-32.002354,45.638897,-12.923597,9.0057535,68.55957,-48.6127,14.450801,44.0551,-38.456764,8.355208,-29.25869,53.37412,21.8441,0.3694898,16.556383,-14.395767,72.706436,-3.9957201,-13.522801,50.227215,51.043934,-59.076115,6.9293046,33.81152,-33.760017,-2.2103357,-5.226387,-58.324112,64.97968,-65.89794,-52.774307,-20.408907,-50.915066,1.3829212,6.5455503,5.370606,54.66508,3.2795312,-62.054142,-11.136138,-5.4901896,-49.254116,22.998478,-4.6770177,74.15929,46.26388,-17.681591,-48.802826,26.573881,0.5723916,18.601532,33.442654,-48.78629,-60.26057,-47.405144,-70.50074,41.77383,-75.48746,-34.267647,13.064281,73.41124,9.269474,-32.679756,35.312824,7.7607594,16.4077,-33.19819,51.93974,38.720024,30.672962,32.194412,-26.206726,10.393266,79.05456,3.135023,28.155897,50.22116,-60.80209,-68.359825,14.828864,1.4756312,-72.205696,34.215015,-41.391796,3.0007348,4.56834,29.568441,-18.44015,-65.612915,14.7041235,-53.861744,-40.219448,-51.38425,24.817493,26.550257,47.050285,-17.64759,18.060772,-41.347404,58.428967,-3.9011476,-36.59335,59.261505,52.586823,-6.8409076,-29.854439,65.45269,-78.705284,-73.08445,34.35634,30.382116,40.407852,53.276474,23.67572,-25.720192,-24.132784,-64.05921,48.397144,-37.572094,-49.007427,-25.08271,-14.7194805,78.776024,68.50301,28.66621,-45.728275,23.833021,24.939531,20.157455,-20.49857,-15.558753,-12.555197,-18.220627,19.873846,37.67127,-11.252915,5.3535466,-33.06868,60.55608,-16.607573,-9.484012,45.759113,15.617465,-44.55049,-2.775656,-3.7670076,-39.270523,15.332291],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d934c4de-31e6-4939-9e06-2fdfc570435b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# También se pueden guardar los vectores y labels como tsv para graficar en\n",
        "# http://projector.tensorflow.org/\n",
        "\n",
        "\n",
        "vectors = np.asarray(w2v_model.wv.vectors)\n",
        "labels = list(w2v_model.wv.index_to_key)\n",
        "\n",
        "np.savetxt(\"vectors.tsv\", vectors, delimiter=\"\\t\")\n",
        "\n",
        "with open(\"labels.tsv\", \"w\") as fp:\n",
        "    for item in labels:\n",
        "        fp.write(\"%s\\n\" % item)"
      ],
      "metadata": {
        "id": "sys4lcG4hEYR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusión general del modelo\n",
        "\n",
        "El modelo en general aprendió bastante bien las relaciones entre palabras dentro del universo de Avengers. No se quedó solo con significados literales, sino que captó conexiones narrativas, personajes, objetos clave y escenas recurrentes. Por ejemplo, entendió que *iron* está más asociado a guerra y tecnología que al metal en sí, o que *war* tiene más que ver con estrategia y personajes como War Machine que con conflicto directo.\n",
        "\n",
        "También se ven asociaciones interesantes con conceptos como *stones*, donde aparecen palabras relacionadas al tiempo, humanidad y el hecho de reunirlas, lo que muestra que el modelo absorbió la estructura de la historia y no solo las frases. Incluso en casos como *captain*, se notan conexiones con libertad, amenazas y su origen artificial, lo que marca que el modelo entendió bien su rol dentro del grupo.\n",
        "\n",
        "En resumen, el modelo captó no solo las palabras, sino el contexto y la dinámica del guion. No es perfecto, pero muestra un aprendizaje bastante sólido sobre los vínculos clave del universo narrativo.\n"
      ],
      "metadata": {
        "id": "Ng7SR-04Lzoi"
      }
    }
  ]
}